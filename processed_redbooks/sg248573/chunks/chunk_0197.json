{
  "content": "model_name=model_name, model_url=model_url, prompt_url=prompt_url, prompt_additional_info=prompt_additional_info ) prompt_template = PromptTemplate( input=input_text, prompt_variables=prompt_variables, input_prefix=input_prefix, output_prefix=output_prefix, model_parameters = model_parameter ) external_prompt_template_details = facts_client.assets.create_detached_prompt( name=prompt_name, description=prompt_description, model_id=model_id, task_id=task_id, prompt_details=prompt_template, detached_information=detached_prompt_template ) project_pta_id = external_prompt_template_details.to_dict()[\"asset_id\"] Once the detached prompt template is created, it follows the same lifecycle as described in 6.4.2, \u201cConsiderations for lifecycle governance for traditional ML hosted on watsonx.ai\u201d on page 70. Note: The following pseudo-code requires additional code to function properly. For more information, see the notebook and the API documentation. 74 Ensuring Trustworthy AI with IBM",
  "metadata": {
    "title": "Ensuring Trustworthy AI with IBM watsonx.governance",
    "author": "IBM",
    "date": "D:20250127103457Z",
    "abstract": null,
    "keywords": [
      "IBM Redbooks IBM Cloud IBM Research IBM Watson OpenPages SPSS Microsoft Red Hat OpenShift RStudio"
    ],
    "file_name": "sg248573.pdf",
    "file_size": 2989189,
    "page_count": 104,
    "processed_date": "2025-03-17T13:37:13.182879",
    "chunk_number": 197,
    "word_count": 84
  }
}